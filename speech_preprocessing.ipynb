{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle \n",
    "import audiosegment \n",
    "from helper import *\n",
    "from features import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(frames, freq, options):\n",
    "    window_sec = 0.2\n",
    "    window_n = int(freq * window_sec)\n",
    "\n",
    "    st_f = stFeatureExtraction(frames, freq, window_n, window_n / 2)\n",
    "\n",
    "    if st_f.shape[1] > 2:\n",
    "        i0 = 1\n",
    "        i1 = st_f.shape[1] - 1\n",
    "        if i1 - i0 < 1:\n",
    "            i1 = i0 + 1\n",
    "        \n",
    "        deriv_st_f = np.zeros((st_f.shape[0], i1 - i0), dtype=float)\n",
    "        for i in range(i0, i1):\n",
    "            i_left = i - 1\n",
    "            i_right = i + 1\n",
    "            deriv_st_f[:st_f.shape[0], i - i0] = st_f[:, i]\n",
    "        return deriv_st_f\n",
    "    elif st_f.shape[1] == 2:\n",
    "        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
    "        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
    "        return deriv_st_f\n",
    "    else:\n",
    "        deriv_st_f = np.zeros((st_f.shape[0], 1), dtype=float)\n",
    "        deriv_st_f[:st_f.shape[0], 0] = st_f[:, 0]\n",
    "        return deriv_st_f\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framerate = 16000\n",
    "data_path = '/IEMOCAP_full_release/'\n",
    "with open(data_path + 'data_collected.pickle', 'rb') as handle:\n",
    "    data2 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = [s['signal'] for s in data2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voiced_feat = []\n",
    "duration = 0.1\n",
    "threshold = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(speech)):\n",
    "    x_head = data2[i]['signal']\n",
    "    #x_head = speech[i]\n",
    "    seg = audiosegment.from_numpy_array(speech[i], framerate)\n",
    "    seg = seg.filter_silence(duration_s=duration, threshold_percentage=threshold)\n",
    "    st_features = calculate_features(seg.to_numpy_array(), framerate, None)\n",
    "    #st_features = calculate_features(x_head, framerate, None)\n",
    "    st_features, _ = pad_sequence_into_array(st_features, maxlen=100)\n",
    "    voiced_feat.append(st_features.T)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voiced_feat = np.array(voiced_feat)\n",
    "voiced_feat.shape\n",
    "np.save('speech.npy', voiced_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
